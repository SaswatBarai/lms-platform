networks:
  lms-network:
    driver: bridge
    name: lms-network
  internal_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
  public_net:
    driver: bridge

services:

  postgres:
    image: postgres:16-alpine
    container_name: postgres_cont
    environment:
      - POSTGRES_USER=lms_user
      - POSTGRES_PASSWORD=lms_pass
      - POSTGRES_DB=lms_db
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks:
      - internal_net
      - lms-network
  
  redis:
    image: redis:7-alpine
    container_name: redis_cont
    command: ["redis-server", "--requirepass", "redis_pass"]
    volumes:
    - redisdata:/data
    networks:
    - internal_net
    - lms-network

  redis-ui:
    image: redis/redisinsight:latest
    container_name: redis_ui
    ports:
      - "5540:5540"
    depends_on:
      - redis
    networks:
      - internal_net
      - lms-network

  # HashiCorp Vault for secrets management
  vault:
    image: hashicorp/vault:1.15
    container_name: lms-vault
    environment:
      VAULT_ADDR: 'http://0.0.0.0:8200'
      VAULT_API_ADDR: 'http://0.0.0.0:8200'
      VAULT_DEV_ROOT_TOKEN_ID: 'dev-root-token'
      VAULT_DEV_LISTEN_ADDRESS: '0.0.0.0:8200'
    command: vault server -dev -dev-listen-address=0.0.0.0:8200 -dev-root-token-id=dev-root-token
    ports:
      - "8200:8200"
    volumes:
      - vault_data:/vault/data
      - vault_logs:/vault/logs
      - ./vault/policies:/vault/policies:ro
    cap_add:
      - IPC_LOCK
    networks:
      - lms-network
      - internal_net
    healthcheck:
      test: ["CMD", "sh", "-c", "VAULT_ADDR=http://localhost:8200 vault status"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  mongo:
    image: mongo:7
    container_name: mongo_cont
    environment:
      - MONGO_INITDB_ROOT_USERNAME=mongoadmin
      - MONGO_INITDB_ROOT_PASSWORD=mongopass
    networks:
      - internal_net

  # MinIO for S3-compatible storage (bulk imports)
  minio:
    image: minio/minio:latest
    container_name: minio_cont
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin123
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    networks:
      - internal_net
      - lms-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # MinIO bucket initialization
  minio-init:
    image: minio/mc:latest
    container_name: minio_init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set myminio http://minio:9000 minioadmin minioadmin123;
      mc mb myminio/lms-bulk-imports --ignore-existing;
      mc anonymous set download myminio/lms-bulk-imports;
      exit 0;
      "
    networks:
      - internal_net
      - lms-network

#================Kong Gateway================#

  kong:
    build:
      context: ./gateway
      dockerfile: kong/Dockerfile
    container_name: lms-kong-gateway
    environment:
      # Basic Kong configuration
      KONG_DATABASE: 'off'
      KONG_DECLARATIVE_CONFIG: '/etc/kong/kong.yaml'
      KONG_PROXY_ACCESS_LOG: '/dev/stdout'
      KONG_ADMIN_ACCESS_LOG: '/dev/stdout'
      KONG_PROXY_ERROR_LOG: '/dev/stderr'
      KONG_ADMIN_ERROR_LOG: '/dev/stderr'
      KONG_ADMIN_LISTEN: '0.0.0.0:8001'
      KONG_PROXY_LISTEN: '0.0.0.0:8000'
      
      # SSL/TLS configuration (for production)
      KONG_SSL_CERT: '/etc/kong/ssl/cert.pem'
      KONG_SSL_CERT_KEY: '/etc/kong/ssl/key.pem'
      
      # Plugin configuration
      KONG_PLUGINS: 'bundled,paseto-vault-auth-lua'
      
      # Vault integration
      KONG_VAULT_ENV_PREFIX: 'KONG_VAULT_'
      KONG_VAULT_KONG_PLUGIN_TOKEN: 'kong-plugin-vault-token'
      
      # Performance tuning
      KONG_WORKER_PROCESSES: '2'
      KONG_WORKER_CONNECTIONS: '1024'
      
      # Logging
      KONG_LOG_LEVEL: 'info'
      KONG_ACCESS_LOG: '/var/log/kong/access.log'
      KONG_ERROR_LOG: '/var/log/kong/error.log'
      
      # Security
      KONG_HEADERS: 'off'
      KONG_TRUSTED_IPS: '0.0.0.0/0,::/0'
      
    ports:
      - "8000:8000"  # Proxy HTTP
      - "8443:8443"  # Proxy HTTPS  
      - "8001:8001"  # Admin API HTTP
      - "8444:8444"  # Admin API HTTPS
    volumes:
      - ./gateway/kong/kong.yaml:/etc/kong/kong.yaml:ro
      - ./gateway/kong/ssl:/etc/kong/ssl:ro  # SSL certificates
      - kong_logs:/var/log/kong
    networks:
      - lms-network
      - internal_net
    depends_on:
      vault:
        condition: service_healthy
      auth-service:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 30s
      timeout: 10s
      retries: 3

#================Ngnix================#

  nginx:
    image: nginx:alpine
    container_name: nginx_lb
    ports:
      - "8080:80"
      - "8445:443"
    volumes:
      - ./gateway/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - kong
    networks:
      - public_net
      - internal_net
      - lms-network

#================Kafka & Zookeeper================#

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper_cont
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2182:2181"
    networks:
      - internal_net
  
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka_cont
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9094"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    ports:
      - "9094:9092"
    networks:
      - internal_net
      - lms-network
    depends_on:
      - zookeeper
    restart: always
  
  kafka-ui:
    image: provectuslabs/kafka-ui:latest  
    container_name: kafka_ui
    ports:
      - "8081:8080"
    environment: 
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: "local"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka:29092"
    depends_on:
      - kafka
    networks:
      - internal_net




#================LMS Services================#

  auth-service:
    build: ./services/auth-service
    container_name: auth_service
    dns:
      - 8.8.8.8
      - 8.8.4.4
    environment:
      - PORT=4001
      - NODE_ENV=development
      - DATABASE_URL=postgresql://lms_user:lms_pass@postgres:5432/lms_db
      - REDIS_URL=redis://:redis_pass@redis:6379/0
      - OTP_SECRET=your_super_secret_otp_key_here_at_least_32_characters_long
      - KAFKA_BROKERS=kafka:29092
      - KAFKA_CLIENT_ID=auth-service
      - KAFKA_GROUP_ID=auth-group
      # Vault configuration
      - VAULT_ADDR=http://vault:8200
      - VAULT_TOKEN=dev-root-token
      - VAULT_NAMESPACE=
      - VAULT_KEY_PATH=lms/paseto/keys
      - VAULT_TIMEOUT=10000
      - VAULT_RETRY_ATTEMPTS=3
      # PASETO configuration
      - PASETO_ACCESS_TOKEN_EXPIRES_IN=1 day
      - PASETO_REFRESH_TOKEN_EXPIRES_IN=7 days
      - PASETO_ISSUER=lms-auth-service
      - PASETO_AUDIENCE=lms-platform
      - SWAGGER_PATH=/app/swagger
      # S3/MinIO configuration (for bulk imports)
      - AWS_REGION=us-east-1
      - S3_ENDPOINT=http://minio:9000
      - S3_BUCKET_NAME=lms-bulk-imports
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin123
    volumes:
      - ./services/auth-service/docs/swagger:/app/swagger:ro
    expose:
      - "4001"
    depends_on:
      - postgres
      - redis
      - mongo
      - kafka
      - vault
      - minio
    networks:
      - internal_net
      - lms-network
    ports:
      - "5555:5555" # for the prisma studio
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4001/auth/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: always

  notification-service:
    build: ./services/notification-service
    container_name: notification_service
    dns:
      - 8.8.8.8
      - 8.8.4.4
    environment:
      - PORT=4002
      - NODE_ENV=development
      - KAFKA_BROKERS=kafka:29092
      - KAFKA_CLIENT_ID=notification-service
      - KAFKA_GROUP_ID=notification-group
      - MAIL_USER=saswatbarai612@gmail.com
      - MAIL_PASS=muxlslrawvhyxtkj
      - MAIL_HOST=smtp.gmail.com
      - MAIL_PORT=587
      # Set to 'console' to disable email and use console logging for development
      # Set to 'email' to enable actual email sending (requires proper Gmail setup)
      - EMAIL_MODE=console
    expose:
      - "4002"
    depends_on:
      kafka:
        condition: service_started
      postgres:
        condition: service_started
    networks:
      - internal_net
      - lms-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: always

  infrastructure-service:
    build: ./services/infrastructure-service
    container_name: infrastructure_service
    dns:
      - 8.8.8.8
      - 8.8.4.4
    environment:
      - PORT=4003
      - NODE_ENV=development
      - KAFKA_BROKERS=kafka:29092
      - KAFKA_CLIENT_ID=infrastructure-service
      - KAFKA_GROUP_ID=infrastructure-group
    expose:
      - "4003"
    depends_on:
      - kafka
    networks:
      - internal_net
      - lms-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: always

  bulk-import-service:
    build: ./services/bulk-import-service
    container_name: bulk_import_service
    dns:
      - 8.8.8.8
      - 8.8.4.4
    environment:
      - PORT=4004
      - NODE_ENV=development
      - DATABASE_URL=postgresql://lms_user:lms_pass@postgres:5432/lms_db
      - REDIS_URL=redis://:redis_pass@redis:6379/0
      - KAFKA_BROKERS=kafka:29092
      - KAFKA_CLIENT_ID=bulk-import-service
      - KAFKA_GROUP_ID=bulk-import-group
      # S3/MinIO configuration
      - AWS_REGION=us-east-1
      - S3_ENDPOINT=http://minio:9000
      - S3_BUCKET_NAME=lms-bulk-imports
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin123
    expose:
      - "4004"
    depends_on:
      postgres:
        condition: service_started
      redis:
        condition: service_started
      kafka:
        condition: service_started
      minio:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    networks:
      - internal_net
      - lms-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:4004/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: always
    


# ================= Monitoring Stack ================= #

  prometheus:
    image: prom/prometheus:latest
    container_name: lms_prometheus
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/prometheus/rules:/etc/prometheus/rules
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    networks:
      - lms-network
      - internal_net

  grafana:
    image: grafana/grafana:latest
    container_name: lms_grafana
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - lms-network
      - internal_net
    depends_on:
      - prometheus

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: lms_elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - lms-network
      - internal_net
    deploy:
      resources:
        limits:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: lms_kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    networks:
      - lms-network
      - internal_net
    depends_on:
      elasticsearch:
        condition: service_healthy

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: lms_filebeat
    user: root
    volumes:
      - ./monitoring/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: filebeat -e -strict.perms=false
    networks:
      - internal_net
    depends_on:
      - elasticsearch
      - kibana

  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: lms_jaeger
    ports:
      - "16686:16686" # UI
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    networks:
      - lms-network
      - internal_net

volumes:
  pgdata:
  redisdata:
  mongodata:
  vault_data:
  vault_logs:
  kong_logs:
  minio_data:
  elasticsearch_data:





